import streamlit as st
import pandas as pd
import plotly.express as px
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

st.set_page_config(page_title="Dashboard Inteligente de Testes", layout="wide")

st.title("üß© Dashboard Inteligente de Casos de Teste")
st.markdown("""
Este painel identifica **problemas estruturais, redund√¢ncias e padr√µes** nos casos de teste.
""")

# ==============================
# LEITURA DOS ARQUIVOS
# ==============================
st.sidebar.header("üìÅ Configura√ß√µes")
data_dir = st.sidebar.text_input("Caminho da pasta com os arquivos CSV", "dados")

if os.path.exists(data_dir):
    csv_files = [f for f in os.listdir(data_dir) if f.endswith(".csv")]

    if csv_files:
        dfs = []
        for file in csv_files:
            try:
                df = pd.read_csv(os.path.join(data_dir, file), encoding="utf-8", sep=None, engine="python")
            except UnicodeDecodeError:
                df = pd.read_csv(os.path.join(data_dir, file), encoding="latin1", sep=None, engine="python")

            df.columns = [
                "Story Link", "TC ID", "T√≠tulo do Teste", "Pr√©-condi√ß√£o",
                "Passos", "Resultado Esperado", "Resultado Execu√ß√£o", "Bug", "Prioridade"
            ]
            df["Arquivo"] = file
            dfs.append(df)

        data = pd.concat(dfs, ignore_index=True)
        data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)

        # ==============================
        # FILTRO POR PRIORIDADE
        # ==============================
        st.sidebar.subheader("Filtro de Prioridade")
        prioridades = sorted(data["Prioridade"].dropna().unique().tolist())
        prioria_filtro = st.sidebar.multiselect("Selecione prioridades", prioridades, default=prioridades)

        if len(prioria_filtro) > 0:
            data = data[data["Prioridade"].isin(prioria_filtro)]

        # ==============================
        # M√âTRICAS DERIVADAS
        # ==============================
        data["Qtd Passos"] = data["Passos"].apply(lambda x: len(str(x).split("\n")) if pd.notna(x) else 0)
        data["Tem Pr√©-condi√ß√£o"] = data["Pr√©-condi√ß√£o"].notna()
        data["Tem Passos"] = data["Passos"].notna()
        data["Tem Resultado Esperado"] = data["Resultado Esperado"].notna()
        data["Tem Bug"] = data["Bug"].notna()
        data["Tamanho Steps"] = data["Passos"].apply(lambda x: len(str(x)) if pd.notna(x) else 0)
        data["Tamanho Resultado"] = data["Resultado Esperado"].apply(lambda x: len(str(x)) if pd.notna(x) else 0)

        # ==============================
        # STATUS DOS TESTES
        # ==============================
        st.subheader("üìä Status dos Testes")

        total_testes = len(data)
        passaram = data["Resultado Execu√ß√£o"].str.contains("PASSED|OK|SUCESS", case=False, na=False).sum()
        falharam = data["Resultado Execu√ß√£o"].str.contains("FAILED|ERRO|FAILED", case=False, na=False).sum()
        nao_exec = data["Resultado Execu√ß√£o"].str.contains("N√ÉO EXECUTADO|NAO EXECUTADO", case=False, na=False).sum()


        # ==============================
        # M√âTRICAS GERAIS
        # ==============================
        col1, col2, col3, col4,col5,col6 = st.columns(6)
        col1.metric("Total de Testes", len(data))
        col2.metric("Passaram", passaram)
        col3.metric("Com Pr√©-condi√ß√£o", data["Tem Pr√©-condi√ß√£o"].sum())
        col4.metric("Falharam", falharam)
        col5.metric("Com Bug Reportado", data["Tem Bug"].sum())
        col6.metric("Sem Resultado Esperado", len(data) - data["Tem Resultado Esperado"].sum())

        # ==============================
        # DISTRIBUI√á√ïES E GR√ÅFICOS
        # ==============================
        st.subheader("üìà Estrutura e Complexidade dos Testes")

        fig1 = px.histogram(data, x="Qtd Passos", nbins=20, title="Distribui√ß√£o da Quantidade de Passos")
        st.plotly_chart(fig1, width="stretch")

        fig2 = px.box(data, y="Tamanho Steps", color="Prioridade", title="Comprimento dos Steps por Prioridade")
        st.plotly_chart(fig2, width="stretch")

        # ==============================
        # TESTES EXTREMOS
        # ==============================
        st.subheader("‚ö†Ô∏è Testes com Estrutura An√¥mala")

        longos = data[data["Qtd Passos"] > data["Qtd Passos"].mean() + 2*data["Qtd Passos"].std()]
        curtos = data[data["Qtd Passos"] < max(1, data["Qtd Passos"].mean() - data["Qtd Passos"].std())]

        if len(longos) > 0:
            st.markdown(f"üîπ **{len(longos)} testes** com passos excessivos (complexos demais).")
            st.dataframe(longos[["TC ID", "T√≠tulo do Teste", "Qtd Passos", "Prioridade"]])
        else:
            st.info("Nenhum teste excessivamente longo encontrado.")

        if len(curtos) > 0:
            st.markdown(f"üîπ **{len(curtos)} testes** com poucos passos (potencialmente mal definidos).")
            st.dataframe(curtos[["TC ID", "T√≠tulo do Teste", "Qtd Passos", "Prioridade"]])

        # ==============================
        # DENSIDADE DE BUGS POR PRIORIDADE
        # ==============================
        st.subheader("üêû Densidade de Bugs por Prioridade")
        bugs_por_prioridade = data.groupby("Prioridade")["Tem Bug"].mean().reset_index()
        bugs_por_prioridade["Tem Bug"] = bugs_por_prioridade["Tem Bug"] * 100
        fig3 = px.bar(bugs_por_prioridade, x="Prioridade", y="Tem Bug",
                      title="Percentual de Testes com Bug por Prioridade", text_auto=".1f")
        st.plotly_chart(fig3, width="stretch")

        # ==============================
        # SIMILARIDADE ENTRE TESTES
        # ==============================
        st.subheader("üîç Testes com Steps Muito Parecidos")

        stopwords_pt = [
            "de","a","o","e","que","do","da","em","para","com","n√£o","uma","os","no","se",
            "na","por","as","dos","como","mas","foi","ao","ele","das","tem","√†","seu","sua",
            "ou","ser","quando","muito","nos","j√°","est√°","eu","tamb√©m","s√≥","pelo","pela",
            "at√©","isso","ela","entre","sem","mesmo","me","esse","eles","voc√™","meu","minha"
        ]

        data = data.reset_index(drop=True)  # <- preven√ß√£o KeyError

        tfidf = TfidfVectorizer(stop_words=stopwords_pt)
        tfidf_matrix = tfidf.fit_transform(data["Passos"].fillna(""))

        sim_matrix = cosine_similarity(tfidf_matrix)
        similares = []
        for i in range(len(sim_matrix)):
            for j in range(i + 1, len(sim_matrix)):
                if sim_matrix[i, j] > 0.7:
                    similares.append((data.loc[i, "TC ID"], data.loc[j, "TC ID"], round(sim_matrix[i, j], 2)))

        if similares:
            sim_df = pd.DataFrame(similares, columns=["Teste A", "Teste B", "Similaridade"])
            st.dataframe(sim_df, height=300)
        else:
            st.info("Nenhum par de testes com alta similaridade (limiar > 0.7).")

        # ==============================
        # RESULTADOS REPETIDOS
        # ==============================
        st.subheader("üîÅ Testes com Mesmo Resultado Esperado")

        resultado_repetido = data["Resultado Esperado"].value_counts()
        duplicados = resultado_repetido[resultado_repetido > 1].index.tolist()
        if duplicados:
            rep = data[data["Resultado Esperado"].isin(duplicados)][
                ["TC ID", "T√≠tulo do Teste", "Resultado Esperado", "Prioridade"]
            ]
            st.dataframe(rep, height=300)
        else:
            st.info("Nenhum resultado esperado repetido encontrado.")

    else:
        st.warning("Nenhum arquivo CSV encontrado na pasta especificada.")
else:
    st.info("Informe o caminho da pasta com os arquivos CSV (ex: `dados/`).")
